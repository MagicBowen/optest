# optest

A Python-based CLI framework for validating AI operators (CUDA GPU / NPU) with autogenerated inputs and NumPy reference implementations. optest streamlines authoring test plans, executing kernels against stub or custom backends, and producing terminal/JSON reports for rapid regression diagnostics.

- Built-in coverage for common operators: elementwise ops, GEMM, Conv2D, pooling, activations.
- Deterministic NumPy data generation, dtype/shape overrides, YAML plan ingestion.
- Backend abstraction for GPU/NPU drivers plus a reference-backed stub for self-tests.
- Extensible reporters (TTY summary, strict-schema JSON) suitable for automation.

See `docs/optest_design_plan.md` for the roadmap and `docs/optest_architecture.md` for architectural details, extension guidance, and packaging tips.

## Installation

### Local development (editable)
```bash
python3 -m venv .venv
source .venv/bin/activate
pip install -e .
```

### From a released package
```bash
pip install optest  # replace with your published package name if different
```

## CLI Usage

### Quick start
Run a single operator with CLI overrides:
```bash
optest run \
  --op elementwise_add \
  --dtype float32,float32 \
  --shape input0=2x2 \
  --shape input1=2x2
```

### Using YAML plans
Create `plan.yaml`:
```yaml
backend: gpu
chip: a100
seed: 123
report:
  format: json
  path: ./reports/a100_suite.json
cases:
  - op: gemm
    dtypes: [float32, float32]
    shapes:
      input0: [64, 128]
      input1: [128, 256]
    tolerance:
      abs: 1e-4
      rel: 1e-5
  - op: conv2d
    shapes:
      input0: [1, 64, 112, 112]
      input1: [64, 64, 3, 3]
    attr:
      stride: [1, 1]
      padding: same
```
Run it:
```bash
optest run --plan plan.yaml --report json
```

Show CLI help/flags:
```bash
optest -h   # or: optest --help
```

### Key options
- `--op/-o NAME`: specify operators (repeatable). `--plan` can define multiple cases.
- `--dtype a,b,...`: comma-separated dtype tuple per operator input.
- `--shape key=2x3x4`: override tensor shapes (repeat for multiple inputs).
- `--attr key=value`: set operator attributes; accepts YAML literals/tuples.
- `--backend {gpu,npu}` / `--chip name`: choose hardware target.
- `--report {terminal,json}` and `--report-path PATH`: control output format.
- `--no-color`: disable ANSI colors in terminal reporter.
- `--generator dotted.path` / `--reference dotted.path`: override data and golden generation.
- `--tolerance abs=1e-4,rel=1e-5`: on-the-fly tolerance controls.
- `--fail-fast`, `--seed`, `--config` (YAML), etc.

### Running Ascend operator binaries
Use the built-in Ascend backend to reuse existing run scripts/binaries:

```yaml
cases:
  - op: relu
    shapes:
      input0: [8, 2048]
      output0: [8, 2048]
    backend_config:
      ascend:
        workdir: /path/to/add_custom
        command: ["bash", "run.sh", "-r", "cpu", "-v", "Ascend910B"]
        inputs:
          - tensor: input0
            path: input/input_x.bin
            dtype: float16
        outputs:
          - tensor: output0
            path: output/output_z.bin
            dtype: float16
```

`workdir` points at your operator project (containing `run.sh`, `input/`, `output/`). optest writes NumPy-generated tensors into `input/*.bin`, executes the `command`, then reads the configured output files before comparing against reference results. Specify `--backend npu --chip ascend910b` (or whichever SOC you target) to activate this backend.

Use `optest run --help` for the full option list.

## Diagnosing Failures
- The terminal reporter now prints richer failure blocks (backend + chip, seed, shapes, tolerance, and per-tensor mismatch stats including the worst index plus actual/expected values) and a consolidated failure summary at the end of the run.
- Validate error handling for real Ascend command launches with the provided plan under `tmp/add_custom/optest_plan_failure.yaml` (assumes execution from the repo root; adjust `backend_config.ascend.workdir` otherwise):
  ```bash
  PYTHONPATH=src optest run --plan tmp/add_custom/optest_plan_failure.yaml --no-color
  ```
  The plan calls `simulate_failure.sh`, which exits with code 42 so you can confirm optest surfaces the failing command and stderr when an operator invocation breaks.

## Extending Operators & Backends
- Register operator descriptors or swap defaults via plugin modules imported before CLI execution (`OPTEST_PLUGINS=my_pkg.plugins`).
- Implement custom backends by subclassing `BackendDriver` and registering via `backend_manager.register(...)`. See `docs/optest_architecture.md#3-extending-optest-with-custom-gpunpu-backends` for detailed guidance, including the Ascend command backend.

## Packaging & Distribution
- Build distributables with `python -m build` (outputs wheel + sdist under `dist/`).
- Publish to your chosen package index with `python -m twine upload dist/*`.
- Ship company-specific backends/generators as companion packages that depend on `optest` and auto-register plugins on import.

## Reporting
- Terminal reporter shows streaming progress and per-tensor mismatch summaries.
- JSON reporter (schema version `1.0.0`) emits machine-readable results for dashboards/CI pipelines.
- Enable JSON via `--report json --report-path ./reports/latest.json`.

## Additional Documentation
- `docs/optest_design_plan.md` – project goals, phased plan, and risks.
- `docs/optest_architecture.md` – mermaid architecture diagram, core components, extension instructions, packaging guidance.
